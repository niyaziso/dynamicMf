{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynamicMF \n",
    "\n",
    "From resource usage statistics (file **./Data/Zdat.p**), produce the resulting factorizations and store them in **./Data/Results/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "tf.set_random_seed(1) # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "max_iter = 5000 # maximum iterations\n",
    "\n",
    "K_list= [3, 5, 10] # the list of K values that we use in this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_dat = pickle.load(open('./Data/Zdat.p', 'rb')) # T x N x M\n",
    "N = np.shape(Z_dat)[1] # number of nodes in cluster\n",
    "M = np.shape(Z_dat)[2]   # number of statistics that measure cluster performance\n",
    "T = np.shape(Z_dat)[0] # number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in K_list:# range(min_K,max_K + 1):\n",
    "    print(K)\n",
    "    # variables of the models\n",
    "    U_bar = tf.get_variable(name = \"U_bar_\" + str(K), shape = [N, K], dtype = tf.float64)\n",
    "    U_hat = tf.get_variable(name = \"U_hat_\" + str(K), shape = [T, N, K], dtype = tf.float64)\n",
    "    V = tf.get_variable(name = \"V_\" + str(K), shape = [M, K], dtype = tf.float64)\n",
    "\n",
    "    # data of the models\n",
    "    Z = tf.placeholder(dtype = tf.float64, shape = [T, N, M], name = \"Z_\" + str(K))\n",
    "\n",
    "    # computation\n",
    "    temp = U_bar * U_hat\n",
    "    V_t = tf.transpose(V)\n",
    "    temp2 = tf.tile(input = V_t, multiples=[T, 1])\n",
    "    temp2 = tf.reshape(temp2, shape = [T, K, M])\n",
    "    Z_approx = tf.matmul(temp, temp2)\n",
    "    \n",
    "    # loss function\n",
    "    loss = tf.reduce_sum(tf.square(Z_approx - Z))\n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    \n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # training loop\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init) # reset values to wrong\n",
    "    error_val = []\n",
    "    for i in range(max_iter):\n",
    "        train_val, loss_val, U_bar_res, U_hat_res, V_res = sess.run([train, loss, U_bar, U_hat, V], {Z: Z_dat})\n",
    "        if (i % 100 == 0):\n",
    "            print('iter ' + str(i) + ':' + str(loss_val))\n",
    "        error_val.append(loss_val)\n",
    "        \n",
    "    ##### write reconstruction error in each iteration to text file #####\n",
    "    with open('./Data/log/error_' + str(K) + '.txt', 'w') as out:\n",
    "        for error in error_val:\n",
    "            out.write(\"%s\\n\" % error)\n",
    "            \n",
    "    #### store result into result folder ####\n",
    "    pickle.dump([V_res, U_bar_res, U_hat_res], open('./Data/Result/dynMF_' + str(K) + '.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
